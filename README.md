# Language-Translation-using-NMT-and-LSTM
**Successful implementation of Neural Machine Translation (NMT) with a focus on the Encoder-Decoder architecture and LSTM networks.
Addressed the critical need for accurate language translation, recognizing limitations in traditional methods.**

The Sequence-to-Sequence architecture, powered by Recurrent Neural Networks (RNN), showcased robust translation capabilities.

Key technologies, including One Hot Encoding and GloVe word embeddings, played crucial roles in data transformation and enhancing contextual understanding.

_Achieved train accuracy of approximately 87% and test accuracy of around 77%, indicating strong learning and generalization capabilities._

![image](https://github.com/Arpit-Sagar/Language-Translation-using-NMT-and-LSTM/assets/96679459/ea54ff56-2c0c-4e45-813b-e7d597cbca00)

![image](https://github.com/Arpit-Sagar/Language-Translation-using-NMT-and-LSTM/assets/96679459/a1336d9a-b563-4ab6-8331-5676444033da)

![image](https://github.com/Arpit-Sagar/Language-Translation-using-NMT-and-LSTM/assets/96679459/2c78dd2b-a309-4c82-867a-8829ab37a88d)


![image](https://github.com/Arpit-Sagar/Language-Translation-using-NMT-and-LSTM/assets/96679459/f81d3793-2d8c-4ca3-a009-32ee9b45261b)


![image](https://github.com/Arpit-Sagar/Language-Translation-using-NMT-and-LSTM/assets/96679459/409982e9-b5b7-440c-b5b9-c676128bd7a6)


![image](https://github.com/Arpit-Sagar/Language-Translation-using-NMT-and-LSTM/assets/96679459/089cf3f3-9f3c-4d31-ad42-efd7e427f528)
